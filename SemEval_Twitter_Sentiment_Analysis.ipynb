{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets\n",
    "\n",
    "Sentiment analysis is performed on the `SemEval-2017` dataset to predict whether Tweets have a negative, positive or neutral sentiment.\n",
    "\n",
    "### Objectives\n",
    "This notebook aims to employ some classical ML methods as well as LSTM based neural networks to perform the sentiment analysis task. The inputs to all classic ML models will be `Tf-Idf` vectors of each Tweet (after pre-processing). The LSTM model will be trained using `GloVe` embeddings as the input features. The models will then be compared to analyse which approach appears to work best.\n",
    "\n",
    "#### Models Trained\n",
    "- Linear SVM\n",
    "- Naive Bayes Classifier\n",
    "- Logistic Regression\n",
    "- LSTM\n",
    "\n",
    "***Note***: Training time of Kernalized SVM scales quadratically with number of training samples. It was found to be taking too long to converge with the 45,000 samples on hand and was thus dropped from the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import re\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test sets\n",
    "testsets = ['twitter-test1.txt', 'twitter-test2.txt', 'twitter-test3.txt']\n",
    "\n",
    "#Define paths for semeval data and GloVe Embedding data\n",
    "semeval_path = './semeval-tweets'\n",
    "glove_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton: Evaluation code for the test sets\n",
    "def read_test(testset):\n",
    "    '''\n",
    "    readin the testset and return a dictionary\n",
    "    \n",
    "    Args:\n",
    "        testset: str, the file name of the testset to compare\n",
    "    '''\n",
    "    id_gts = {}\n",
    "    with open(testset, 'r', encoding='utf8') as fh:\n",
    "        for line in fh:\n",
    "            fields = line.split('\\t')\n",
    "            tweetid = fields[0]\n",
    "            gt = fields[1]\n",
    "\n",
    "            id_gts[tweetid] = gt\n",
    "\n",
    "    return id_gts\n",
    "\n",
    "\n",
    "def confusion(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the confusion matrix of {'positive', 'netative'} between preds and testset\n",
    "    \n",
    "    Args:\n",
    "        id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "        testset: str, the file name of the testset to compare\n",
    "        classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    gts = []\n",
    "    for m, c1 in id_gts.items():\n",
    "        if c1 not in gts:\n",
    "            gts.append(c1)\n",
    "\n",
    "    gts = ['positive', 'negative', 'neutral']\n",
    "\n",
    "    conf = {}\n",
    "    for c1 in gts:\n",
    "        conf[c1] = {}\n",
    "        for c2 in gts:\n",
    "            conf[c1][c2] = 0\n",
    "\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "        conf[pred][gt] += 1\n",
    "\n",
    "    print(''.ljust(12) + '  '.join(gts))\n",
    "\n",
    "    for c1 in gts:\n",
    "        print(c1.ljust(12), end='')\n",
    "        for c2 in gts:\n",
    "            if sum(conf[c1].values()) > 0:\n",
    "                print('%.3f     ' % (conf[c1][c2] / float(sum(conf[c1].values()))), end='')\n",
    "            else:\n",
    "                print('0.000     ', end='')\n",
    "        print('')\n",
    "\n",
    "    print('')\n",
    "\n",
    "\n",
    "def evaluate(id_preds, testset, classifier):\n",
    "    '''\n",
    "    print the macro-F1 score of {'positive', 'netative'} between preds and testset\n",
    "    \n",
    "    Args:\n",
    "        id_preds: a dictionary of predictions formated as {<tweetid>:<sentiment>, ... }\n",
    "        testset: str, the file name of the testset to compare\n",
    "        classifier: str, the name of the classifier\n",
    "    '''\n",
    "    id_gts = read_test(testset)\n",
    "\n",
    "    acc_by_class = {}\n",
    "    for gt in ['positive', 'negative', 'neutral']:\n",
    "        acc_by_class[gt] = {'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0}\n",
    "\n",
    "    catf1s = {}\n",
    "\n",
    "    ok = 0\n",
    "    for tweetid, gt in id_gts.items():\n",
    "        if tweetid in id_preds:\n",
    "            pred = id_preds[tweetid]\n",
    "        else:\n",
    "            pred = 'neutral'\n",
    "\n",
    "        if gt == pred:\n",
    "            ok += 1\n",
    "            acc_by_class[gt]['tp'] += 1\n",
    "        else:\n",
    "            acc_by_class[gt]['fn'] += 1\n",
    "            acc_by_class[pred]['fp'] += 1\n",
    "\n",
    "    catcount = 0\n",
    "    itemcount = 0\n",
    "    macro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    micro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "    semevalmacro = {'p': 0, 'r': 0, 'f1': 0}\n",
    "\n",
    "    microtp = 0\n",
    "    microfp = 0\n",
    "    microtn = 0\n",
    "    microfn = 0\n",
    "    for cat, acc in acc_by_class.items():\n",
    "        catcount += 1\n",
    "\n",
    "        microtp += acc['tp']\n",
    "        microfp += acc['fp']\n",
    "        microtn += acc['tn']\n",
    "        microfn += acc['fn']\n",
    "\n",
    "        p = 0\n",
    "        if (acc['tp'] + acc['fp']) > 0:\n",
    "            p = float(acc['tp']) / (acc['tp'] + acc['fp'])\n",
    "\n",
    "        r = 0\n",
    "        if (acc['tp'] + acc['fn']) > 0:\n",
    "            r = float(acc['tp']) / (acc['tp'] + acc['fn'])\n",
    "\n",
    "        f1 = 0\n",
    "        if (p + r) > 0:\n",
    "            f1 = 2 * p * r / (p + r)\n",
    "\n",
    "        catf1s[cat] = f1\n",
    "\n",
    "        n = acc['tp'] + acc['fn']\n",
    "\n",
    "        macro['p'] += p\n",
    "        macro['r'] += r\n",
    "        macro['f1'] += f1\n",
    "\n",
    "        if cat in ['positive', 'negative']:\n",
    "            semevalmacro['p'] += p\n",
    "            semevalmacro['r'] += r\n",
    "            semevalmacro['f1'] += f1\n",
    "\n",
    "        itemcount += n\n",
    "\n",
    "    micro['p'] = float(microtp) / float(microtp + microfp)\n",
    "    micro['r'] = float(microtp) / float(microtp + microfn)\n",
    "    micro['f1'] = 2 * float(micro['p']) * micro['r'] / float(micro['p'] + micro['r'])\n",
    "\n",
    "    semevalmacrof1 = semevalmacro['f1'] / 2\n",
    "\n",
    "    print(testset + ' (' + classifier + '): %.3f' % semevalmacrof1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training set, dev set and testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set, dev set and testing set\n",
    "data = {}\n",
    "tweetids = {}\n",
    "tweetgts = {}\n",
    "tweets = {}\n",
    "\n",
    "for dataset in ['twitter-training-data.txt'] + testsets + ['twitter-dev-data.txt']:\n",
    "    data[dataset] = []\n",
    "    tweets[dataset] = []\n",
    "    tweetids[dataset] = []\n",
    "    tweetgts[dataset] = []\n",
    "\n",
    "    # write code to read in the datasets here\n",
    "    with open(os.path.join(semeval_path, dataset)) as f:\n",
    "        f_data = f.readlines()\n",
    "    \n",
    "    f_data = [x.strip() for x in f_data]\n",
    "    data[dataset] = f_data\n",
    "    tweets[dataset] = [x.split('\\t')[2] for x in f_data]\n",
    "    tweetids[dataset] = [x.split('\\t')[0] for x in f_data]\n",
    "    tweetgts[dataset] = [x.split('\\t')[1] for x in f_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "Each tweet is pre-processed to remove profile tags, hashtags and URL's.\n",
    "Stemming/Lemmatization has been shelved for the moment to analyse performance without the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to pre-process tweets from a given dataset\n",
    "def pre_process(tweets_list):\n",
    "    tweets_list = [x.lower() for x in tweets_list]\n",
    "    \n",
    "    #removing profile tags\n",
    "    tweets_list = [re.sub(r'@\\w+\\s', '', x) for x in tweets_list]\n",
    "    \n",
    "    #removing URL's\n",
    "    tweets_list = [re.sub(r'http[s]?://[\\w./\\-?]+', '', x) for x in tweets_list]\n",
    "    \n",
    "    #removing hashtags\n",
    "    tweets_list = [re.sub(r'#\\w+\\s', '', x) for x in tweets_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(len(tweets_list))\n",
    "    for i,text in enumerate(tweets_list):\n",
    "        processed = ''.join([x for x in text if x.isalnum() or x==' '])\n",
    "        tweets_list[i] = processed\n",
    "    #tweets_list = [''.join([x for text in tweets_list for x in text if x.isalnum() or x==' '])]\n",
    "    \n",
    "    return tweets_list\n",
    "\n",
    "\n",
    "#pre-process all the tweets across datasets\n",
    "for k in tweets:\n",
    "    tweets[k] = pre_process(tweets[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get number of training samples\n",
    "len(tweets['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Class distribution of Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 15986, 'negative': 8326, 'neutral': 20789})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train data\n",
    "Counter(tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vocab = set()\n",
    "for tw in tweets['twitter-training-data.txt']:\n",
    "    tokens = word_tokenize(tw)\n",
    "    train_vocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48090"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling with SMOTE to get a balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, we see that the classes are imbalanced in the training set. The ratio is roughly `negative:positive:neutral = 2: 1.5 :1`. Two standard approaches to balance datasets are downsampling and upsampling. Considering the size of train set is limited, undersampling is avoided and SMOTE is used to generate some new training samples using information from existing training samples.\n",
    "\n",
    "The performance of the models will be compared on both original and SMOTE applied datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 15986, 'negative': 8326, 'neutral': 20789})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original class distribution\n",
    "Counter(tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words=None, max_features=5000, min_df=5)\n",
    "tfidf = tvec.fit_transform(tweets['twitter-training-data.txt'])\n",
    "X_smote, y_smote = SMOTE(random_state=10).fit_resample(tfidf, tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'positive': 20789, 'negative': 20789, 'neutral': 20789})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class distribution after SMOTE\n",
    "Counter(y_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression with Tf-Idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words=None, max_features=5000, min_df=5)\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tvec.fit_transform(tweets['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeff/anaconda3/envs/analysis/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#tfidf_train = tvec.fit_transform(tweets['twitter-training-data.txt'])\n",
    "#tfidf_val = tvec.fit_transform(tweets['twitter-training-data.txt'][-2000:])\n",
    "lr_model = lr.fit(tfidf, tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'positive', 'neutral',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_test = tvec.transform(tweets['twitter-test1.txt'])\n",
    "prediction = lr_model.predict(tfidf_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 166  322   69]\n",
      " [  26 1203  275]\n",
      " [  29  531  910]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.30      0.43       557\n",
      "     neutral       0.59      0.80      0.68      1504\n",
      "    positive       0.73      0.62      0.67      1470\n",
      "\n",
      "    accuracy                           0.65      3531\n",
      "   macro avg       0.69      0.57      0.59      3531\n",
      "weighted avg       0.67      0.65      0.63      3531\n",
      "\n",
      "0.6454262248654772\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],prediction))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],prediction))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SMOTE dataset below, the model showed an improvement of about 8% in the F1 score for the negative class (which earlier models were struggling with). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeff/anaconda3/envs/analysis/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Using SMOTE training data\n",
    "model_lr_smote = lr.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'positive', 'neutral',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_lr_smote.predict(tfidf_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 255  230   72]\n",
      " [ 108 1007  389]\n",
      " [  87  413  970]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.46      0.51       557\n",
      "     neutral       0.61      0.67      0.64      1504\n",
      "    positive       0.68      0.66      0.67      1470\n",
      "\n",
      "    accuracy                           0.63      3531\n",
      "   macro avg       0.62      0.60      0.60      3531\n",
      "weighted avg       0.63      0.63      0.63      3531\n",
      "\n",
      "0.6321155480033984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],prediction))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],prediction))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear SVM with Tf-Idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVM\n",
    "lin_clf = svm.LinearSVC()\n",
    "lin_svm_model = lin_clf.fit(tfidf, tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'negative', 'neutral',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tfidf_test = tvec.transform(tweets['twitter-test1.txt'])\n",
    "lin_svm_preds = lin_svm_model.predict(tfidf_test)\n",
    "lin_svm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 194  289   74]\n",
      " [  43 1175  286]\n",
      " [  44  518  908]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.35      0.46       557\n",
      "     neutral       0.59      0.78      0.67      1504\n",
      "    positive       0.72      0.62      0.66      1470\n",
      "\n",
      "    accuracy                           0.64      3531\n",
      "   macro avg       0.67      0.58      0.60      3531\n",
      "weighted avg       0.66      0.64      0.64      3531\n",
      "\n",
      "0.6448598130841121\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], lin_svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM (with class weights specified)\n",
    "Linear SVM has an option to provide `class weights` to the model prior to training. This is another way to deal with imbalanced classes, especially if the minority class is of bigger importance to us.\n",
    "\n",
    "The results show a 7% improvement in the F1 score of the negative class and an improvement of 2% in the overall macro average F1 score (compared to linear SVM model fit without class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf_weighted = svm.LinearSVC(class_weight={'negative':2, 'neutral':1, 'positive':1.5})\n",
    "lin_svm_model_weighted = lin_clf_weighted.fit(tfidf, tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'negative', 'positive',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm_preds = lin_svm_model_weighted.predict(tfidf_test)\n",
    "lin_svm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 254  222   81]\n",
      " [  79 1046  379]\n",
      " [  67  438  965]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.46      0.53       557\n",
      "     neutral       0.61      0.70      0.65      1504\n",
      "    positive       0.68      0.66      0.67      1470\n",
      "\n",
      "    accuracy                           0.64      3531\n",
      "   macro avg       0.64      0.60      0.62      3531\n",
      "weighted avg       0.64      0.64      0.64      3531\n",
      "\n",
      "0.6414613423959218\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], lin_svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM (using SMOTE enhanced train data)\n",
    "Trying Linear SVM with SMOTE, the performance **degraded** compared to model fit with original data (class weights specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf_smote = svm.LinearSVC()\n",
    "lin_svm_model_smote = lin_clf_smote.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'negative', 'neutral',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_svm_preds = lin_svm_model_smote.predict(tfidf_test)\n",
    "lin_svm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[281 202  74]\n",
      " [159 957 388]\n",
      " [108 408 954]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.51      0.50      0.51       557\n",
      "     neutral       0.61      0.64      0.62      1504\n",
      "    positive       0.67      0.65      0.66      1470\n",
      "\n",
      "    accuracy                           0.62      3531\n",
      "   macro avg       0.60      0.60      0.60      3531\n",
      "weighted avg       0.62      0.62      0.62      3531\n",
      "\n",
      "0.6207873123760974\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],lin_svm_preds))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], lin_svm_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes with Tf-Idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.fit(tfidf, tweetgts['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'neutral', ..., 'positive', 'neutral',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_nb = nb_model.predict(tfidf_test)\n",
    "predictions_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  52  403  102]\n",
      " [   5 1172  327]\n",
      " [   6  596  868]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.09      0.17       557\n",
      "     neutral       0.54      0.78      0.64      1504\n",
      "    positive       0.67      0.59      0.63      1470\n",
      "\n",
      "    accuracy                           0.59      3531\n",
      "   macro avg       0.68      0.49      0.48      3531\n",
      "weighted avg       0.64      0.59      0.56      3531\n",
      "\n",
      "0.5924667233078448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],predictions_nb))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],predictions_nb))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], predictions_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The results for Naive Bayes trained on the original dataset shows really poor performance on the minority negative class. Training the same model on the SMOTE dataset shows a significant improvement, as shown below. The overall macro average F1 score goes up by 9% and F1 score for the minority class goes up by 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model_smote = naive_bayes.MultinomialNB()\n",
    "nb_model_smote.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'neutral', ..., 'positive', 'positive',\n",
       "       'neutral'], dtype='<U8')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_nb = nb_model_smote.predict(tfidf_test)\n",
    "predictions_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 272  181  104]\n",
      " [ 136  796  572]\n",
      " [ 114  337 1019]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.52      0.49      0.50       557\n",
      "     neutral       0.61      0.53      0.56      1504\n",
      "    positive       0.60      0.69      0.64      1470\n",
      "\n",
      "    accuracy                           0.59      3531\n",
      "   macro avg       0.58      0.57      0.57      3531\n",
      "weighted avg       0.59      0.59      0.59      3531\n",
      "\n",
      "0.5910506938544322\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(tweetgts['twitter-test1.txt'],predictions_nb))  \n",
    "print(classification_report(tweetgts['twitter-test1.txt'],predictions_nb))  \n",
    "print(accuracy_score(tweetgts['twitter-test1.txt'], predictions_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The conclusion from the above experiments seems to be that SMOTE has indeed helped address the class imbalance problem and the trained models are more robust as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LSTM\n",
    "\n",
    "A simple neural network architecture with a single LSTM layer is designed to predict sentiments for this task. Architecture can be enhanced later to train more complex models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Glove Embeddings\n",
    "Pre-trained 100 dimensional GloVe embeddings are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/glove.6B.100d.txt') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vocab_size = len(lines)\n",
    "glove_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "word2idx = {}\n",
    "vectors = np.zeros((glove_vocab_size, 100))\n",
    "\n",
    "for ix, l in enumerate(lines):\n",
    "    line = l.split()\n",
    "    word = line[0]\n",
    "    words.append(word)\n",
    "    word2idx[word] = ix\n",
    "    vect = np.array(line[1:]).astype(np.float32)\n",
    "    vectors[ix] = vect\n",
    "    \n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next step is to identify the top 5000 words from train set vocab to use in the LSTM's embedding layer. This is done here with the help of Tf-Idf. The top 5000 words with the highest score (essentially highest relevance) is picked from the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_lstm = TfidfVectorizer(stop_words=None, max_features=10000, min_df=5)\n",
    "tfidf_lstm = tvec_lstm.fit_transform(tweets['twitter-training-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '007', '01', ..., 'zuckerman', 'zulu', 'zumba'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tvec_lstm.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lack', '86', 'late', 'driver', 'fear', 'faint', 'italy', 'inter',\n",
       "       'celebrity', 'celebs', 'celine', 'cell', 'cells', 'celtic', 'cena',\n",
       "       'celtics', 'celebrations', 'cenas', 'censor', 'censors', 'cent',\n",
       "       'center', 'central', 'celebrities', 'lifestyle', 'celebration',\n",
       "       'cease', 'cb', 'cba', 'cbb', 'cbs', 'cc', 'cd', 'cdnpoli',\n",
       "       'ceasefire', 'celebrating', 'cebu', 'cedar', 'celeb', 'celebrate',\n",
       "       'celebrated', 'celebrates', 'centuries', 'centre', 'ceremony',\n",
       "       'century', 'challenging', 'chamber', 'chamberlain', 'chambers',\n",
       "       'champ', 'champagne', 'champion', 'champions', 'championship',\n",
       "       'championships', 'champs', 'chance', 'chancellor', 'chances',\n",
       "       'chandler', 'chanel', 'chalmers', 'challenges', 'ceo',\n",
       "       'challenged', 'cavani', 'certain', 'certainly', 'certificate',\n",
       "       'ces', 'cesc', 'cesena', 'cet', 'cfc', 'ch', 'chad', 'chain',\n",
       "       'chair', 'chairman', 'challenge', 'cave', 'causes', 'causing',\n",
       "       'carly', 'carey', 'careys', 'caring', 'carl', 'carling', 'carlos',\n",
       "       'carlton', 'carmelo', 'careless', 'carol', 'carolina', 'carpet',\n",
       "       'carrie', 'carried', 'carrier'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_array = np.array(feature_names)\n",
    "tfidf_sorting = np.argsort(tfidf.toarray()).flatten()[::-1]\n",
    "\n",
    "n = 5000\n",
    "top_vocab = feature_array[tfidf_sorting][:n]\n",
    "\n",
    "#display the top 100\n",
    "top_vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./top_vocab.pkl', 'wb') as p_file:\n",
    "    pickle.dump(top_vocab, p_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping top 5000 vocab to corresponding Glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(top_vocab):\n",
    "    matrix_len = 5000 #vocab size\n",
    "    emb_dim = 100\n",
    "    weights_matrix = np.zeros((matrix_len, emb_dim), dtype='float')\n",
    "    words_found = 0\n",
    "    glove_vocab = glove.keys()\n",
    "\n",
    "    #initialise vocab->ix mapping with padding placeholder and unknown token\n",
    "    emb_vocab_to_idx = {'':0, 'UNK':1}\n",
    "    #initialise vocab list mapping with padding placeholder and unknown token\n",
    "    emb_vocabulary = ['', 'UNK']\n",
    "\n",
    "    #setting a random vector for UNK token\n",
    "    weights_matrix[1] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "\n",
    "    #since we are adding two custom tokens to vocab, the last two words from top vocab is dropped\n",
    "    # to maintain vocab size of 5000. For the same reason, all indexing is offset by 2 below\n",
    "    for i, word in enumerate(top_vocab[:-2]):\n",
    "        #if word exists in Glove, use Glove embedding\n",
    "        if word in glove_vocab: \n",
    "            weights_matrix[i+2] = glove[word]\n",
    "            #keep count of how many words are actually present in Glove\n",
    "            words_found += 1\n",
    "\n",
    "        #if word not in Glove, initialise with a random vector\n",
    "        else:\n",
    "            weights_matrix[i+2] = np.random.normal(scale=0.6, size=(emb_dim, ))\n",
    "\n",
    "        emb_vocab_to_idx[word] = i+2\n",
    "        emb_vocabulary.append(word)\n",
    "        \n",
    "    return weights_matrix, emb_vocab_to_idx, emb_vocabulary, words_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try fetching the embeddings of the top vocab words\n",
    "weights_matrix, emb_vocab_to_idx, emb_vocabulary, words_found = get_glove_embeddings(top_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4824"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_found #majority of words are already present in Glove, this is good! (4824/5000 are present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the tweets in Glove's embedding space\n",
    "\n",
    "First, the size of the document vector to be fed into the neural network has to be determined. The tweets in the training data are analysed to figure this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lengths = []\n",
    "for tweet in tweets['twitter-training-data.txt']:\n",
    "    cur_length = len(word_tokenize(tweet))\n",
    "    all_lengths.append(cur_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.578834172191304"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(all_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The average length of the tweets in train set is 17.5 words(tokens) and longest tweet is 35 words(tokens)\n",
    "With this in mind, a document length of 20 is chosen to accomodate for the vast majority of tweets with padding whenever necessary.\n",
    "\n",
    "***Note***: Choosing a very large document length would just feed a lot of heavily padded vectors to the network and this will not help with its training/convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode tweets into embedding space with a document vector length of 20\n",
    "def encode_tweet(text, vocab_conv_to_idx, N=20):\n",
    "    tokenized = word_tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab_conv_to_idx.get(word, vocab_conv_to_idx[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the training data\n",
    "train_X = []\n",
    "for tweet in tweets['twitter-training-data.txt']:\n",
    "    encoding = encode_tweet(tweet, emb_vocab_to_idx)\n",
    "    train_X.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2685,    1,    1,    1,    1, 3459,    1, 1474, 2795,    1,  651,\n",
       "          1,    1, 2295, 3995,    1, 3459,  952,    1,    1])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[10] #sample encoded vector - the 1's correspond to 'UNK' tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the validation data\n",
    "val_X = []\n",
    "for tweet in tweets['twitter-dev-data.txt']:\n",
    "    encoding = encode_tweet(tweet, emb_vocab_to_idx)\n",
    "    val_X.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3066, 2062, 4630,    1,    1,    1, 2693, 4448, 3673,    1,    1,\n",
       "          1, 3092,    1, 4588,  936,    1,    1,    1,    1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Torch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining custom dataset class to use for the dataloader\n",
    "class twitterDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #mapping categorical labels to integers\n",
    "        class_mapping = {'negative':0, 'neutral':1, 'positive':2}\n",
    "        return torch.from_numpy(self.X[idx].astype(np.int32)), class_mapping.get(self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train/val datasets\n",
    "train_ds = twitterDataset(train_X, tweetgts['twitter-training-data.txt'])\n",
    "valid_ds = twitterDataset(val_X, tweetgts['twitter-dev-data.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying batch and vocab size\n",
    "batch_size = 2048\n",
    "vocab_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataloaders\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1,    1,    1,  ...,    0,    0,    0],\n",
      "        [   1,    1, 3459,  ...,    0,    0,    0],\n",
      "        [   1, 3377,    1,  ...,    1,    0,    0],\n",
      "        ...,\n",
      "        [   1,    1, 4578,  ...,    0,    0,    0],\n",
      "        [   1, 3092,    1,  ...,    0,    0,    0],\n",
      "        [   1, 1573,    1,  ...,    1, 2971,  926]], dtype=torch.int32) tensor([2, 2, 1,  ..., 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#display data from the first training batch\n",
    "for x,y in train_dl:\n",
    "    print(x,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture\n",
    "\n",
    "***Note***: A softmax layer seems intuitive for this multi-class classification task, however the three output values from the linear layer when taken as the final output led to better convergence and this was employed in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_custom(torch.nn.Module) :\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, glove_weights) :\n",
    "        '''\n",
    "        Custom LSTM model incorporating pre-trained GloVe embeddings.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: size of vocabulary in the embedding layer (5000 in this case)\n",
    "            embedding_dim: GloVe_vector dimension\n",
    "            hidden_dim: size of output from the hidden state of LSTM\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(glove_weights))\n",
    "        \n",
    "        # Freeze embedding layer so that pre-trained Glove embeddings don't get updated while training\n",
    "        self.embeddings.weight.requires_grad = False\n",
    "        \n",
    "        #specify the LSTM layer that follows the embedding layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        #linear layer to compute three values corresponding to each of the three sentiments\n",
    "        self.linear = nn.Linear(hidden_dim, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Perform a single forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            x: input to network\n",
    "        \n",
    "        Returns:\n",
    "            torch_tensor: final output of the neural network after forward pass\n",
    "        '''\n",
    "        #encoded doc vector (seq_len=20) is fed to embedding layer\n",
    "        x = self.embeddings(x)\n",
    "        #drop out to try avoid overfitting\n",
    "        x = self.dropout(x)\n",
    "        #embeddings of size (seq_len=20, emb_dim=100) are generated and fed to lstm\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        #the ht(hidden_state) output of the lstm is taken and fed to the final linear layer\n",
    "        x = self.linear(ht[-1])\n",
    "        \n",
    "        #the scores for the three classes outputted by the linear layer is the final output of network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dl, val_dl, epochs=10, lr=0.001, patience=5):\n",
    "    '''\n",
    "    Function to train the PyTorch model\n",
    "    \n",
    "    Args:\n",
    "        model: torch NN model\n",
    "        train_dl: DataLoader for training data\n",
    "        val_dl: DataLoader for validation data\n",
    "        epochs: number of training epochs\n",
    "        lr: learning rate\n",
    "        patience: number of epochs to wait without improvement in validation score before halting training\n",
    "    '''\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    comp = float('inf')\n",
    "    \n",
    "    #patience = 5\n",
    "    #patience_window_train_loss = []\n",
    "    #patience_window_val_loss = []\n",
    "    best_train_loss, best_val_loss = float('inf'), float('inf')\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x)\n",
    "            #print(y_pred)\n",
    "            #print(y_pred.shape)\n",
    "            #break\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print('Epoch-{} : '.format(i), \"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "            \n",
    "        if i%patience == 0:\n",
    "            if val_loss < best_val_loss:\n",
    "                print('Epoch-{} Val Loss Improved! Saving Model to Disk.'.format(i))\n",
    "                torch.save(model.state_dict(), './best_lstm_model.pt')\n",
    "                best_val_loss = val_loss\n",
    "                \n",
    "            else:\n",
    "                print('Val Loss did not improve within patience window. Stop Training.')\n",
    "                return None\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = LSTM_custom(vocab_size, embedding_dim=100, hidden_dim=50, glove_weights=weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-0 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-1 :  train loss 0.981, val loss 0.946, val accuracy 0.513, and val rmse 0.825\n",
      "Epoch-6 :  train loss 0.867, val loss 0.855, val accuracy 0.593, and val rmse 0.689\n",
      "Epoch-10 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-11 :  train loss 0.835, val loss 0.844, val accuracy 0.604, and val rmse 0.714\n",
      "Epoch-16 :  train loss 0.812, val loss 0.839, val accuracy 0.599, and val rmse 0.694\n",
      "Val Loss did not improve within patience window. Stop Training.\n"
     ]
    }
   ],
   "source": [
    "train_model(lstm_model, epochs=200, lr=0.01, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load best model\n",
    "best_model = LSTM_custom(vocab_size, embedding_dim=100, hidden_dim=50, glove_weights=weights_matrix)\n",
    "best_model.load_state_dict(torch.load('./best_lstm_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8704016208648682, tensor(0.5750), 0.7671375365604267)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_metrics(lstm_model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n",
    "The LSTM model was overfitting quite easily when trained without an early-stopping condition. Even with early stopping, the model's performance on the validation set doesn't seem to be a true reflection of generalization, and on the test set performance suffers as shown in cells below.\n",
    "\n",
    "The `patience_window` was thus quite agressive to stop the model training early and combat the overfitting issue. However, performance on the test set shows that the model has not learned to generalize and there is definitely more work to be done here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating all models (summary)\n",
    "This cell trains and evaluates the different models discussed above to compare them all in once place. The performance metrics are shown for each model across the three different test sets (does NOT include validation set). The evaluation metric displayed is **macro F1 score** (assigning equal importance to all three sentiment classes) for all models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training NB\n",
      "semeval-tweets/twitter-test1.txt (tfidf-NB): 0.398\n",
      "semeval-tweets/twitter-test2.txt (tfidf-NB): 0.430\n",
      "semeval-tweets/twitter-test3.txt (tfidf-NB): 0.404\n",
      "Training LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeff/anaconda3/envs/analysis/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semeval-tweets/twitter-test1.txt (tfidf-LR): 0.547\n",
      "semeval-tweets/twitter-test2.txt (tfidf-LR): 0.554\n",
      "semeval-tweets/twitter-test3.txt (tfidf-LR): 0.511\n",
      "Training SVM\n",
      "semeval-tweets/twitter-test1.txt (tfidf-SVM): 0.599\n",
      "semeval-tweets/twitter-test2.txt (tfidf-SVM): 0.602\n",
      "semeval-tweets/twitter-test3.txt (tfidf-SVM): 0.564\n",
      "Training LSTM\n",
      "Log: Glove data read from disk successfully\n",
      "Log: Creating word->embedding dict for all words in Glove vocabulary...\n",
      "Log: Fitting Tf-Idf vectoriser to train data\n",
      "Log: Converting Tf-Idf to dense representation\n",
      "Log: Identified top 5000 words from train set vocabulary\n",
      "Log: Creating embedding matrix using Glove vectors for our custom top vocabulary\n",
      "Log: Encoding Train data\n",
      "Log: Encoding Validation data\n",
      "Log: Creating data loaders for train and validation data\n",
      "Log: Instantiating custom LSTM model\n",
      "Log: Starting LSTM training\n",
      "Epoch-0 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-1 :  train loss 1.001, val loss 0.961, val accuracy 0.501, and val rmse 0.729\n",
      "Epoch-5 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-6 :  train loss 0.881, val loss 0.867, val accuracy 0.581, and val rmse 0.742\n",
      "Epoch-10 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-11 :  train loss 0.845, val loss 0.844, val accuracy 0.604, and val rmse 0.688\n",
      "Epoch-15 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-16 :  train loss 0.822, val loss 0.837, val accuracy 0.612, and val rmse 0.708\n",
      "Epoch-20 Val Loss Improved! Saving Model to Disk.\n",
      "Epoch-21 :  train loss 0.806, val loss 0.835, val accuracy 0.620, and val rmse 0.689\n",
      "Val Loss did not improve within patience window. Stop Training.\n",
      "Log: Training Complete\n",
      "Log: Loading best trained model from disk\n",
      "semeval-tweets/twitter-test1.txt (glove-LSTM): 0.104\n",
      "semeval-tweets/twitter-test2.txt (glove-LSTM): 0.244\n",
      "semeval-tweets/twitter-test3.txt (glove-LSTM): 0.045\n"
     ]
    }
   ],
   "source": [
    "#class mapping to convert int to categorical labels\n",
    "class_map = {0:'negative', 1:'neutral', 2:'positive'}\n",
    "\n",
    "#creating Tf-Idf representation of the train data as this is used across all models for training\n",
    "tvec = TfidfVectorizer(stop_words=None, max_features=5000, min_df=5)\n",
    "tfidf = tvec.fit_transform(tweets['twitter-training-data.txt'])\n",
    "\n",
    "for classifier in ['NB', 'LR', 'SVM', 'LSTM']:\n",
    "    for features in ['tfidf', 'glove']:\n",
    "        # Skeleton: Creation and training of the classifiers\n",
    "        if classifier == 'LR':\n",
    "            if features != 'tfidf':\n",
    "                continue\n",
    "            print('Training ' + classifier)\n",
    "            #instantiate LR model\n",
    "            lr = LogisticRegression()\n",
    "            #train model\n",
    "            model = lr.fit(tfidf, tweetgts['twitter-training-data.txt'])\n",
    "            \n",
    "        elif classifier == 'SVM':\n",
    "            if features != 'tfidf':\n",
    "                continue\n",
    "            print('Training ' + classifier)\n",
    "            #instantiate SVM model\n",
    "            lin_clf_weighted = svm.LinearSVC(class_weight={'negative':2, 'neutral':1, 'positive':1.5})\n",
    "            #train model\n",
    "            model = lin_clf_weighted.fit(tfidf, tweetgts['twitter-training-data.txt'])\n",
    "            \n",
    "        elif classifier == 'NB':\n",
    "            if features != 'tfidf':\n",
    "                continue\n",
    "            print('Training ' + classifier)\n",
    "            #instantiate NB model\n",
    "            nb = naive_bayes.MultinomialNB()\n",
    "            #train model\n",
    "            model = nb.fit(tfidf, tweetgts['twitter-training-data.txt'])\n",
    "            \n",
    "        elif classifier == 'LSTM':\n",
    "            # write the LSTM classifier here\n",
    "            if features != 'glove':\n",
    "                continue\n",
    "            print('Training ' + classifier)\n",
    "            \n",
    "            #Read the Glove embeddings\n",
    "            with open(join(glove_path,'glove.6B.100d.txt')) as f:\n",
    "                lines = f.readlines()\n",
    "            print('Log: Glove data read from disk successfully')\n",
    "                \n",
    "            #Load Glove Embeddings into dictionary mapping word->embedding\n",
    "            words = []\n",
    "            word2idx = {}\n",
    "            glove_vocab_size = len(lines)\n",
    "            vectors = np.zeros((glove_vocab_size, 100))\n",
    "            print('Log: Creating word->embedding dict for all words in Glove vocabulary...')\n",
    "            for ix, l in enumerate(lines):\n",
    "                line = l.split()\n",
    "                word = line[0]\n",
    "                words.append(word)\n",
    "                word2idx[word] = ix\n",
    "                vect = np.array(line[1:]).astype(np.float32)\n",
    "                vectors[ix] = vect\n",
    "            #Glove embedding dictionary\n",
    "            glove = {w: vectors[word2idx[w]] for w in words}\n",
    "                \n",
    "            #use TF-Idf to help with choosing the most relevant 5000 words in training voabulary\n",
    "            print('Log: Fitting Tf-Idf vectoriser to train data')\n",
    "            tvec_lstm = TfidfVectorizer(stop_words=None, max_features=10000, min_df=5)\n",
    "            tfidf_lstm = tvec_lstm.fit_transform(tweets['twitter-training-data.txt'])\n",
    "            \n",
    "            \n",
    "            \n",
    "            '''                     WARNING!!!!\n",
    "            The below lines that convert the Tf-Idf matrix from CSR to dense form will consume a lot of RAM.\n",
    "            On my machine with 16GB of RAM, it was just about to manage. If the kernel dies due to a memory\n",
    "            error, please set the 'memory_issue_flag' to True below so that the pickled list of top vocabulary\n",
    "            words can be loaded!\n",
    "            '''\n",
    "            memory_issue_flag = False\n",
    "            \n",
    "            if not memory_issue_flag:\n",
    "                #get list of all features(words) in Tf-Idf feature space\n",
    "                print('Log: Converting Tf-Idf to dense representation')\n",
    "                feature_names = tvec_lstm.get_feature_names_out()\n",
    "                feature_array = np.array(feature_names)\n",
    "                #sort words based on Tf-Idf scores\n",
    "                tfidf_sorting = np.argsort(tfidf.toarray()).flatten()[::-1]\n",
    "\n",
    "                #fetching top 5000 words\n",
    "                n = 5000\n",
    "                top_vocab = feature_array[tfidf_sorting][:n]\n",
    "                \n",
    "            else:\n",
    "                print('Log: Loading top vocab words from pickle file to avoid memory issue')\n",
    "                with open('./top_vocab.pkl', 'rb') as p_file:\n",
    "                    top_vocab = pickle.load(p_file)\n",
    "            \n",
    "            print('Log: Identified top 5000 words from train set vocabulary')\n",
    "            \n",
    "            #helper function to get Glove embeddings for top words(i.e our custom vocabulary)\n",
    "            print('Log: Creating embedding matrix using Glove vectors for our custom top vocabulary')\n",
    "            weights_matrix, emb_vocab_to_idx, emb_vocabulary, _ = get_glove_embeddings(top_vocab)\n",
    "            \n",
    "            #encoding the training data as vectors of indices to index into custom vocabulary glove embeddings\n",
    "            print('Log: Encoding Train data')\n",
    "            train_X = []\n",
    "            for tweet in tweets['twitter-training-data.txt']:\n",
    "                encoding = encode_tweet(tweet, emb_vocab_to_idx)\n",
    "                train_X.append(encoding)\n",
    "                \n",
    "            #encoding the validation data\n",
    "            print('Log: Encoding Validation data')\n",
    "            val_X = []\n",
    "            for tweet in tweets['twitter-dev-data.txt']:\n",
    "                encoding = encode_tweet(tweet, emb_vocab_to_idx)\n",
    "                val_X.append(encoding)\n",
    "                \n",
    "            #specifying batch size for datasets/dataloaders\n",
    "            batch_size = 2048\n",
    "            vocab_size = 5000\n",
    "                \n",
    "            #creating dataset and dataloader for training\n",
    "            train_ds = twitterDataset(train_X, tweetgts['twitter-training-data.txt'])\n",
    "            valid_ds = twitterDataset(val_X, tweetgts['twitter-dev-data.txt'])\n",
    "            \n",
    "            #creating dataloaders\n",
    "            print('Log: Creating data loaders for train and validation data')\n",
    "            train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "            val_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "            \n",
    "            #instantiate custom LSTM model using class defined earlier\n",
    "            print('Log: Instantiating custom LSTM model')\n",
    "            lstm_model = LSTM_custom(vocab_size, embedding_dim=100, hidden_dim=50, glove_weights=weights_matrix)\n",
    "            #train network using helper function defined earlier\n",
    "            print('Log: Starting LSTM training')\n",
    "            train_model(lstm_model, train_dl, val_dl, epochs=50, lr=0.01)\n",
    "            print('Log: Training Complete')\n",
    "            \n",
    "            #load the best model from disk\n",
    "            print('Log: Loading best trained model from disk')\n",
    "            best_model = LSTM_custom(vocab_size, embedding_dim=100, hidden_dim=50, glove_weights=weights_matrix)\n",
    "            best_model.load_state_dict(torch.load('./best_lstm_model.pt'))\n",
    "            #set model to evaluate mode so that weights don't get updated when running inference\n",
    "            best_model.eval()\n",
    "            \n",
    "        else:\n",
    "            print('Unknown classifier name' + classifier)\n",
    "            continue\n",
    "\n",
    "        # Prediction performance of the classifiers\n",
    "        for testset in testsets:\n",
    "            id_preds = {}\n",
    "            # write the prediction and evaluation code here\n",
    "            \n",
    "            #Inference for LSTM\n",
    "            if classifier == 'LSTM':\n",
    "                #getting encodings for tweets in test set\n",
    "                X_test = []\n",
    "                for tweet in tweets[testset]:\n",
    "                    encoding = encode_tweet(tweet, emb_vocab_to_idx)\n",
    "                    X_test.append(encoding)\n",
    "                \n",
    "                #creating dataloader for test set\n",
    "                test_ds = twitterDataset(X_test, tweetgts[testset])\n",
    "                test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "                \n",
    "                for x, y in test_dl:\n",
    "                    x = x.long()\n",
    "                    y = y.long()\n",
    "                    #run inference on batch\n",
    "                    y_hat = best_model(x)\n",
    "                    preds = torch.max(y_hat, 1)[1].tolist()\n",
    "                    predictions = [class_map[x] for x in preds]\n",
    "            \n",
    "            #For all other models\n",
    "            else:\n",
    "                tfidf_test = tvec.transform(tweets[testset])\n",
    "                predictions = model.predict(tfidf_test)\n",
    "            \n",
    "            \n",
    "            for idd, pred in zip(tweetids[testset], predictions):\n",
    "                id_preds[idd] = pred\n",
    "\n",
    "            testset_name = testset\n",
    "            testset_path = join('semeval-tweets', testset_name)\n",
    "            evaluate(id_preds, testset_path, features + '-' + classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "Debug why the LSTM model is overfitting with such ease and train a more robust model. LSTM's are known to perform very well on NLP tasks and performance here certainly has room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
